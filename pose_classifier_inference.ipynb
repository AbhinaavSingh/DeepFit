{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"-_pijx-MDa52","executionInfo":{"status":"ok","timestamp":1650476331572,"user_tz":240,"elapsed":2722,"user":{"displayName":"Naman Arora","userId":"05431509508560644189"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"qOWnhlSmDa5_","executionInfo":{"status":"ok","timestamp":1650476331574,"user_tz":240,"elapsed":7,"user":{"displayName":"Naman Arora","userId":"05431509508560644189"}}},"outputs":[],"source":["def load_graph(frozen_graph_filename):\n","    # We load the protobuf file from the disk and parse it to retrieve the \n","    # unserialized graph_def\n","    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n","        graph_def = tf.GraphDef()\n","        graph_def.ParseFromString(f.read())\n","\n","    # Then, we import the graph_def into a new Graph and returns it \n","    with tf.Graph().as_default() as graph:\n","        # The name var will prefix every op/nodes in your graph\n","        # Since we load everything in a new graph, this is not needed\n","        tf.import_graph_def(graph_def, name=\"prefix\")\n","    return graph"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Z_0xYbS5Da6B","executionInfo":{"status":"ok","timestamp":1650476333166,"user_tz":240,"elapsed":161,"user":{"displayName":"Naman Arora","userId":"05431509508560644189"}}},"outputs":[],"source":["def load_X(X_path):\n","    file = open(X_path, 'r')\n","    X_ = np.array(\n","        [elem for elem in [\n","            row.split(',') for row in file\n","        ]], \n","        dtype=np.float32\n","    )\n","    file.close()\n","    return X_\n","\n","def euclidean_dist(a, b):\n","    # This function calculates the euclidean distance between 2 point in 2-D coordinates\n","    # if one of two points is (0,0), dist = 0\n","    # a, b: input array with dimension: m, 2\n","    # m: number of samples\n","    # 2: x and y coordinate\n","    try:\n","        if (a.shape[1] == 2 and a.shape == b.shape):\n","            # check if element of a and b is (0,0)\n","            bol_a = (a[:,0] != 0).astype(int)\n","            bol_b = (b[:,0] != 0).astype(int)\n","            dist = np.linalg.norm(a-b, axis=1)\n","            return((dist*bol_a*bol_b).reshape(a.shape[0],1))\n","    except:\n","        print(\"[Error]: Check dimension of input vector\")\n","        return None\n","    \n","def norm_X(X):\n","    num_sample = X.shape[0]\n","    # Keypoints\n","    Nose = X[:,0*2:0*2+2]\n","    Neck = X[:,1*2:1*2+2]\n","    RShoulder = X[:,2*2:2*2+2]\n","    RElbow = X[:,3*2:3*2+2]\n","    RWrist = X[:,4*2:4*2+2]\n","    LShoulder = X[:,5*2:5*2+2]\n","    LElbow = X[:,6*2:6*2+2]\n","    LWrist = X[:,7*2:7*2+2]\n","    RHip = X[:,8*2:8*2+2]\n","    RKnee = X[:,9*2:9*2+2]\n","    RAnkle = X[:,10*2:10*2+2]\n","    LHip = X[:,11*2:11*2+2]\n","    LKnee = X[:,12*2:12*2+2]\n","    LAnkle = X[:,13*2:13*2+2]\n","    REye = X[:,14*2:14*2+2]\n","    LEye = X[:,15*2:15*2+2]\n","    REar = X[:,16*2:16*2+2]\n","    LEar = X[:,17*2:17*2+2]\n","\n","    # Length of head\n","    length_Neck_LEar = euclidean_dist(Neck, LEar)\n","    length_Neck_REar = euclidean_dist(Neck, REar)\n","    length_Neck_LEye = euclidean_dist(Neck, LEye)\n","    length_Neck_REye = euclidean_dist(Neck, REye)\n","    length_Nose_LEar = euclidean_dist(Nose, LEar)\n","    length_Nose_REar = euclidean_dist(Nose, REar)\n","    length_Nose_LEye = euclidean_dist(Nose, LEye)\n","    length_Nose_REye = euclidean_dist(Nose, REye)\n","    length_head      = np.maximum.reduce([length_Neck_LEar, length_Neck_REar, length_Neck_LEye, length_Neck_REye, \\\n","                                 length_Nose_LEar, length_Nose_REar, length_Nose_LEye, length_Nose_REye])\n","    #length_head      = np.sqrt(np.square((LEye[:,0:1]+REye[:,0:1])/2 - Neck[:,0:1]) + np.square((LEye[:,1:2]+REye[:,1:2])/2 - Neck[:,1:2]))\n","\n","    # Length of torso\n","    length_Neck_LHip = euclidean_dist(Neck, LHip)\n","    length_Neck_RHip = euclidean_dist(Neck, RHip)\n","    length_torso     = np.maximum(length_Neck_LHip, length_Neck_RHip)\n","    #length_torso     = np.sqrt(np.square(Neck[:,0:1]-(LHip[:,0:1]+RHip[:,0:1])/2) + np.square(Neck[:,1:2]-(LHip[:,1:2]+RHip[:,1:2])/2))\n","\n","    # Length of right leg\n","    length_leg_right = euclidean_dist(RHip, RKnee) + euclidean_dist(RKnee, RAnkle)\n","    #length_leg_right = np.sqrt(np.square(RHip[:,0:1]-RKnee[:,0:1]) + np.square(RHip[:,1:2]-RKnee[:,1:2])) \\\n","    #+ np.sqrt(np.square(RKnee[:,0:1]-RAnkle[:,0:1]) + np.square(RKnee[:,1:2]-RAnkle[:,1:2]))\n","\n","    # Length of left leg\n","    length_leg_left = euclidean_dist(LHip, LKnee) + euclidean_dist(LKnee, LAnkle)\n","    #length_leg_left = np.sqrt(np.square(LHip[:,0:1]-LKnee[:,0:1]) + np.square(LHip[:,1:2]-LKnee[:,1:2])) \\\n","    #+ np.sqrt(np.square(LKnee[:,0:1]-LAnkle[:,0:1]) + np.square(LKnee[:,1:2]-LAnkle[:,1:2]))\n","\n","    # Length of leg\n","    length_leg = np.maximum(length_leg_right, length_leg_left)\n","\n","    # Length of body\n","    length_body = length_head + length_torso + length_leg\n","    \n","    # Check all samples have length_body of 0\n","    length_chk = (length_body > 0).astype(int)\n","    \n","    # Check keypoints at origin\n","    keypoints_chk = (X > 0).astype(int)\n","    \n","    chk = length_chk * keypoints_chk\n","    \n","    # Set all length_body of 0 to 1 (to avoid division by 0)\n","    length_body[length_body == 0] = 1\n","    \n","    # The center of gravity\n","    # number of point OpenPose locates:\n","    num_pts = (X[:, 0::2] > 0).sum(1).reshape(num_sample,1)\n","    centr_x = X[:, 0::2].sum(1).reshape(num_sample,1) / num_pts\n","    centr_y = X[:, 1::2].sum(1).reshape(num_sample,1) / num_pts\n","\n","    # The  coordinates  are  normalized relative to the length of the body and the center of gravity\n","    X_norm_x = (X[:, 0::2] - centr_x) / length_body\n","    X_norm_y = (X[:, 1::2] - centr_y) / length_body\n","    \n","    # Stack 1st element x and y together\n","    X_norm = np.column_stack((X_norm_x[:,:1], X_norm_y[:,:1]))\n","        \n","    for i in range(1, X.shape[1]//2):\n","        X_norm = np.column_stack((X_norm, X_norm_x[:,i:i+1], X_norm_y[:,i:i+1]))\n","    \n","    # Set all samples have length_body of 0 to origin (0, 0)\n","    X_norm = X_norm * chk\n","    \n","    return X_norm"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ZtQrd9aXDa6G","executionInfo":{"status":"ok","timestamp":1650476334137,"user_tz":240,"elapsed":185,"user":{"displayName":"Naman Arora","userId":"05431509508560644189"}}},"outputs":[],"source":["def plot_line(a, b):\n","    if (a.any()> 0 and b.any()>0): plt.plot([a[0], b[0]], [a[1], b[1]], 'k-')\n","        \n","def plot_skeleton(sample, pattern):\n","    for i in range(len(sample)//2):\n","        plt.plot(sample[i*2], sample[i*2+1], pattern) \n","    skeleton = sample.reshape(1, 36)\n","    Nose = skeleton[:,0*2:0*2+2][0]\n","    Neck = skeleton[:,1*2:1*2+2][0]\n","    RShoulder = skeleton[:,2*2:2*2+2][0]\n","    RElbow = skeleton[:,3*2:3*2+2][0]\n","    RWrist = skeleton[:,4*2:4*2+2][0]\n","    LShoulder = skeleton[:,5*2:5*2+2][0]\n","    LElbow = skeleton[:,6*2:6*2+2][0]\n","    LWrist = skeleton[:,7*2:7*2+2][0]\n","    RHip = skeleton[:,8*2:8*2+2][0]\n","    RKnee = skeleton[:,9*2:9*2+2][0]\n","    RAnkle = skeleton[:,10*2:10*2+2][0]\n","    LHip = skeleton[:,11*2:11*2+2][0]\n","    LKnee = skeleton[:,12*2:12*2+2][0]\n","    LAnkle = skeleton[:,13*2:13*2+2][0]\n","    REye = skeleton[:,14*2:14*2+2][0]\n","    LEye = skeleton[:,15*2:15*2+2][0]\n","    REar = skeleton[:,16*2:16*2+2][0]\n","    LEar = skeleton[:,17*2:17*2+2][0]\n","    #Nose = sample.reshape(1, 36)[:,0*2:0*2+2][0]\n","    #Neck = sample.reshape(1, 36)[:,1*2:1*2+2][0]\n","    plot_line(LEar, LEye)\n","    plot_line(LEye, Nose)\n","    plot_line(REar, REye)\n","    plot_line(REye, Nose)\n","    plot_line(Nose, Neck)\n","    plot_line(Neck, LShoulder)\n","    plot_line(LShoulder, LElbow)\n","    plot_line(LElbow, LWrist)\n","    plot_line(Neck, RShoulder)\n","    plot_line(RShoulder, RElbow)\n","    plot_line(RElbow, RWrist)\n","    plot_line(Neck, LHip)\n","    plot_line(LHip, LKnee)\n","    plot_line(LKnee, LAnkle)\n","    plot_line(Neck, RHip)\n","    plot_line(RHip, RKnee)\n","    plot_line(RKnee, RAnkle)\n","    \n","def plot(sample):\n","    # sample is one-dimension array\n","    # e.g: (36,)\n","    if sample.shape[0] == 36:\n","        sample_norm = norm_X(sample.reshape(1,36))[0]\n","\n","        # Plot original coordinates\n","        pad_ori = 40\n","        plt.figure(str(sample))\n","        plt.subplot(121)\n","        plt.title('Original skeleton')\n","        X_ori = sample\n","        x_max = max(X_ori[0::2]) + pad_ori\n","        x_min = min(i for i in X_ori[0::2] if i > 0) - pad_ori\n","        y_max = max(X_ori[1::2]) + pad_ori\n","        y_min = min(j for j in X_ori[1::2] if j > 0) - pad_ori\n","        plt.xlim(x_min,x_max)\n","        plt.ylim(y_max, y_min)\n","        plot_skeleton(X_ori, 'bo')\n","\n","        # Plot normalized coordinates\n","        pad_nor = 0.2\n","        #plt.figure(2)\n","        plt.subplot(122)\n","        plt.title('Normalized skeleton')\n","        X_nor = sample_norm\n","        x_max = max(X_nor[0::2]) + pad_nor\n","        x_min = min(X_nor[0::2]) - pad_nor\n","        y_max = max(X_nor[1::2]) + pad_nor\n","        y_min = min(X_nor[1::2]) - pad_nor\n","        plt.xlim(x_min,x_max)\n","        plt.ylim(y_max, y_min)\n","        plot_skeleton(X_nor, 'ro')\n","    else:\n","        print(\"[ERROR]: sample is one-dimension array: (36,)\")\n","        print(\"         Current input dimension is: \" + str(sam.shape))"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"IBYKXr5ADa6J","executionInfo":{"status":"error","timestamp":1650476335245,"user_tz":240,"elapsed":403,"user":{"displayName":"Naman Arora","userId":"05431509508560644189"}},"outputId":"7b1c51ba-0fcb-4dfa-914a-de306bb739d8","colab":{"base_uri":"https://localhost:8080/","height":356}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-de29bc743770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load test sample and normalize it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_test_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dataset/X_sample.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mX_test_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-90be92882509>\u001b[0m in \u001b[0;36mload_X\u001b[0;34m(X_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     X_ = np.array(\n\u001b[1;32m      4\u001b[0m         [elem for elem in [\n\u001b[1;32m      5\u001b[0m             \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/X_sample.txt'"]}],"source":["LABELS = [    \n","    \"STANDING\",\n","    \"BENDING\",\n","    \"CROUCHING\"\n","]\n","\n","# Load test sample and normalize it\n","X_test_path = \"dataset/X_sample.txt\"\n","X_test = load_X(X_test_path)\n","X_test_norm = norm_X(X_test)\n","\n","graph_path = 'pose_classifier.h5.pb'\n","graph = load_graph(graph_path)\n","\n","# We can verify that we can access the list of operations in the graph\n","# for op in graph.get_operations():\n","#     print(op.name)\n","        \n","# We access the input and output nodes \n","y = graph.get_tensor_by_name('prefix/output_node0:0')\n","x = graph.get_tensor_by_name('prefix/dense_1_input:0')\n","\n","# We launch a Session\n","with tf.Session(graph=graph) as sess:\n","    # Note: we don't nee to initialize/restore anything\n","    # There is no Variables in this graph, only hardcoded constants \n","    \n","    for i in range(len(X_test_norm)):\n","        sam = X_test_norm[i].reshape(1, 36)\n","        y_out = sess.run(y, feed_dict={x: sam})\n","        print(\"Estimated pose for keypoint set #\" + str(i))\n","        for idx in range(len(LABELS)):\n","            print(\"\\t\" + LABELS[idx] + \": \\t\" + str(y_out[0][idx]))\n","        plot(X_test[i])"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Nesz9en2Da6L","executionInfo":{"status":"ok","timestamp":1650476335680,"user_tz":240,"elapsed":4,"user":{"displayName":"Naman Arora","userId":"05431509508560644189"}}},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"pose_classifier_inference.ipynb","provenance":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}